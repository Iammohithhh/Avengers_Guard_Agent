{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec56059",
   "metadata": {},
   "source": [
    "# 🦾 MILESTONE 2: AVENGERS FACE RECOGNITION SYSTEM\n",
    "## Trusted User Detection & Enrollment\n",
    "\n",
    "**Objective**: Detect and recognize trusted users (you, roommates, friends)\n",
    "\n",
    "**Features**:\n",
    "- Face detection using MediaPipe/face_recognition\n",
    "- Enrollment system for trusted faces\n",
    "- Real-time recognition from webcam\n",
    "- Avengers-themed welcome messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81a826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💻 Running locally. Ensure requirements.txt is installed.\n",
      "✅ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 2: Install Dependencies\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"📦 Installing face recognition packages...\")\n",
    "    # !apt-get -qq install cmake\n",
    "    # !pip install -q face-recognition opencv-python mediapipe pillow\n",
    "else:\n",
    "    print(\"💻 Running locally. Ensure requirements.txt is installed.\")\n",
    "\n",
    "# Cell 3: Import Libraries\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "print(\"✅ All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0f0f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Directories created at data\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Data Classes and Configuration\n",
    "@dataclass\n",
    "class TrustedPerson:\n",
    "    \"\"\"Represents a trusted individual\"\"\"\n",
    "    name: str\n",
    "    role: str  # e.g., \"owner\", \"roommate\", \"friend\"\n",
    "    face_encoding: np.ndarray\n",
    "    enrolled_date: str\n",
    "    photo_path: str\n",
    "    recognition_count: int = 0\n",
    "    \n",
    "    def to_dict(self):\n",
    "        \"\"\"Convert to dictionary for JSON serialization\"\"\"\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'role': self.role,\n",
    "            'face_encoding': self.face_encoding.tolist(),\n",
    "            'enrolled_date': self.enrolled_date,\n",
    "            'photo_path': self.photo_path,\n",
    "            'recognition_count': self.recognition_count\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_dict(data):\n",
    "        \"\"\"Create from dictionary\"\"\"\n",
    "        return TrustedPerson(\n",
    "            name=data['name'],\n",
    "            role=data['role'],\n",
    "            face_encoding=np.array(data['face_encoding']),\n",
    "            enrolled_date=data['enrolled_date'],\n",
    "            photo_path=data['photo_path'],\n",
    "            recognition_count=data.get('recognition_count', 0)\n",
    "        )\n",
    "\n",
    "class FaceRecognitionConfig:\n",
    "    \"\"\"Configuration for face recognition system\"\"\"\n",
    "    \n",
    "    # Paths\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    FACES_DIR = DATA_DIR / \"trusted_faces\" / \"photos\"\n",
    "    EMBEDDINGS_DIR = DATA_DIR / \"trusted_faces\" / \"embeddings\"\n",
    "    DB_FILE = EMBEDDINGS_DIR / \"trusted_persons.pkl\"\n",
    "    \n",
    "    # Recognition parameters\n",
    "    RECOGNITION_TOLERANCE = 0.6  # Lower = stricter (0.4-0.7 recommended)\n",
    "    FACE_DETECTION_MODEL = \"hog\"  # \"hog\" (faster, CPU) or \"cnn\" (accurate, GPU)\n",
    "    MIN_FACE_SIZE = 50  # Minimum face size in pixels\n",
    "    \n",
    "    # Avengers personality mappings\n",
    "    PERSONALITY_GREETINGS = {\n",
    "        \"owner\": [\n",
    "            \"Welcome back, boss. JARVIS has kept everything secure.\",\n",
    "            \"Good to see you, sir. All systems nominal.\",\n",
    "            \"Access granted. Room status: secured.\"\n",
    "        ],\n",
    "        \"roommate\": [\n",
    "            \"Hey roommate! Everything's been quiet here.\",\n",
    "            \"Welcome back. No intruders detected during your absence.\",\n",
    "            \"Access granted. Room secured as usual.\"\n",
    "        ],\n",
    "        \"friend\": [\n",
    "            \"Hello, friend! You're cleared to enter.\",\n",
    "            \"Welcome! JARVIS recognizes you from my database.\",\n",
    "            \"Access granted. Good to see a familiar face.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    INTRUDER_MESSAGES = [\n",
    "        \"Unrecognized individual detected. Please identify yourself.\",\n",
    "        \"Hold on there, stranger. Who are you and what's your business here?\",\n",
    "        \"Access denied. You are not in my database of trusted individuals.\"\n",
    "    ]\n",
    "    \n",
    "    @classmethod\n",
    "    def setup_directories(cls):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        cls.FACES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        cls.EMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"✅ Directories created at {cls.DATA_DIR}\")\n",
    "\n",
    "config = FaceRecognitionConfig()\n",
    "config.setup_directories()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07244641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Enrollment System ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Face Enrollment System (CORRECTED)\n",
    "class FaceEnrollmentSystem:\n",
    "    \"\"\"Handles enrollment of trusted faces\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.config = FaceRecognitionConfig()\n",
    "        self.trusted_persons: Dict[str, TrustedPerson] = {}\n",
    "        self.load_database()\n",
    "    \n",
    "    def enroll_from_image(self, image_path: str, name: str, role: str = \"friend\") -> bool:\n",
    "        \"\"\"\n",
    "        Enroll a person from an image file\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the image file\n",
    "            name: Person's name\n",
    "            role: Role (owner/roommate/friend)\n",
    "        \n",
    "        Returns:\n",
    "            True if enrollment successful\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"📸 ENROLLING: {name} ({role})\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # Load image\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            print(f\"✅ Image loaded: {image.shape}\")\n",
    "            \n",
    "            # Detect faces\n",
    "            face_locations = face_recognition.face_locations(\n",
    "                image, \n",
    "                model=self.config.FACE_DETECTION_MODEL\n",
    "            )\n",
    "            \n",
    "            if len(face_locations) == 0:\n",
    "                print(\"❌ No faces detected in image!\")\n",
    "                return False\n",
    "            \n",
    "            if len(face_locations) > 1:\n",
    "                print(f\"⚠️  Multiple faces detected ({len(face_locations)}). Using the largest face.\")\n",
    "                # Use the largest face\n",
    "                face_locations = [max(face_locations, key=lambda loc: (loc[2] - loc[0]) * (loc[1] - loc[3]))]\n",
    "            \n",
    "            # Get face encoding\n",
    "            face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "            \n",
    "            if len(face_encodings) == 0:\n",
    "                print(\"❌ Could not generate face encoding!\")\n",
    "                return False\n",
    "            \n",
    "            face_encoding = face_encodings[0]\n",
    "            \n",
    "            # Create trusted person object\n",
    "            person = TrustedPerson(\n",
    "                name=name,\n",
    "                role=role,\n",
    "                face_encoding=face_encoding,\n",
    "                enrolled_date=datetime.now().isoformat(),\n",
    "                photo_path=image_path\n",
    "            )\n",
    "            \n",
    "            # Save to database\n",
    "            self.trusted_persons[name] = person\n",
    "            self.save_database()\n",
    "            \n",
    "            print(f\"✅ {name} enrolled successfully!\")\n",
    "            print(f\"   Role: {role}\")\n",
    "            print(f\"   Encoding shape: {face_encoding.shape}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Enrollment failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def enroll_from_webcam(self, name: str, role: str = \"friend\", num_samples: int = 3) -> bool:\n",
    "        \"\"\"\n",
    "        AUTO-CAPTURE VERSION - No space bar needed!\n",
    "        Just look at camera and stay still for 6 seconds\n",
    "        \n",
    "        Args:\n",
    "            name: Person's name\n",
    "            role: Role (owner/roommate/friend)\n",
    "            num_samples: Number of samples to capture (default 3)\n",
    "        \n",
    "        Returns:\n",
    "            True if enrollment successful\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"📹 AUTO-ENROLLMENT: {name} as {role}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(\"📋 Just look at the camera and STAY STILL\")\n",
    "        print(\"📋 System captures automatically every 2 seconds\")\n",
    "        print(\"📋 Press ESC to cancel\\n\")\n",
    "        \n",
    "        # Open webcam\n",
    "        video_capture = cv2.VideoCapture(0)\n",
    "        time.sleep(1)  # Let camera warm up\n",
    "        \n",
    "        if not video_capture.isOpened():\n",
    "            print(\"❌ Cannot open webcam!\")\n",
    "            return False\n",
    "        \n",
    "        print(\"✅ Webcam opened\")\n",
    "        \n",
    "        captured_encodings = []\n",
    "        sample_count = 0\n",
    "        last_capture = 0\n",
    "        \n",
    "        try:\n",
    "            while sample_count < num_samples:\n",
    "                ret, frame = video_capture.read()\n",
    "                \n",
    "                if not ret:\n",
    "                    print(\"⚠️ Can't read frame, retrying...\")\n",
    "                    time.sleep(0.1)\n",
    "                    continue\n",
    "                \n",
    "                # Show frame\n",
    "                display_frame = frame.copy()\n",
    "                \n",
    "                # Add text overlay\n",
    "                cv2.putText(display_frame, f\"Captured: {sample_count}/{num_samples}\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(display_frame, \"Look at camera & stay still\", \n",
    "                           (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                \n",
    "                cv2.imshow('Enrollment - Auto Capture', display_frame)\n",
    "                \n",
    "                # Process keyboard\n",
    "                key = cv2.waitKey(30) & 0xFF\n",
    "                if key == 27:  # ESC\n",
    "                    print(\"\\n❌ Cancelled by user\")\n",
    "                    video_capture.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return False\n",
    "                \n",
    "                # Try to capture every 2 seconds\n",
    "                current_time = time.time()\n",
    "                if current_time - last_capture >= 2.0:\n",
    "                    \n",
    "                    print(f\"📸 Attempting capture {sample_count + 1}...\")\n",
    "                    \n",
    "                    # Convert to RGB\n",
    "                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Detect faces (using fast HOG model)\n",
    "                    print(\"   Detecting faces...\")\n",
    "                    face_locations = face_recognition.face_locations(rgb_frame, model=\"hog\")\n",
    "                    \n",
    "                    print(f\"   Found {len(face_locations)} face(s)\")\n",
    "                    \n",
    "                    if len(face_locations) == 1:\n",
    "                        # Perfect - one face!\n",
    "                        print(\"   Getting face encoding...\")\n",
    "                        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "                        \n",
    "                        if len(face_encodings) > 0:\n",
    "                            # Success!\n",
    "                            captured_encodings.append(face_encodings[0])\n",
    "                            sample_count += 1\n",
    "                            last_capture = current_time\n",
    "                            \n",
    "                            # Save photo\n",
    "                            photo_path = self.config.FACES_DIR / f\"{name}_{sample_count}.jpg\"\n",
    "                            cv2.imwrite(str(photo_path), frame)\n",
    "                            \n",
    "                            print(f\"   ✅ Sample {sample_count}/{num_samples} captured!\\n\")\n",
    "                        else:\n",
    "                            print(\"   ⚠️ Could not encode face, try again...\")\n",
    "                    \n",
    "                    elif len(face_locations) == 0:\n",
    "                        print(\"   ⚠️ No face detected - move closer or improve lighting\\n\")\n",
    "                    else:\n",
    "                        print(f\"   ⚠️ {len(face_locations)} faces detected - only one person please\\n\")\n",
    "                    \n",
    "                    last_capture = current_time  # Update to avoid spam\n",
    "            \n",
    "            # Close webcam\n",
    "            print(\"\\n📷 Closing webcam...\")\n",
    "            video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            time.sleep(0.5)\n",
    "            print(\"✅ Webcam closed\\n\")\n",
    "            \n",
    "            # Save to database\n",
    "            if len(captured_encodings) >= num_samples:\n",
    "                print(\"💾 Saving to database...\")\n",
    "                \n",
    "                # Average the encodings\n",
    "                avg_encoding = np.mean(captured_encodings, axis=0)\n",
    "                \n",
    "                # Create person object\n",
    "                person = TrustedPerson(\n",
    "                    name=name,\n",
    "                    role=role,\n",
    "                    face_encoding=avg_encoding,\n",
    "                    enrolled_date=datetime.now().isoformat(),\n",
    "                    photo_path=str(self.config.FACES_DIR / f\"{name}_1.jpg\")\n",
    "                )\n",
    "                \n",
    "                # Save to database\n",
    "                self.trusted_persons[name] = person\n",
    "                self.save_database()\n",
    "                \n",
    "                print(f\"\\n🎉 SUCCESS! {name} enrolled as {role}\")\n",
    "                print(f\"   Total samples: {len(captured_encodings)}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"❌ Failed to capture enough samples\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ ERROR: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return False\n",
    "    \n",
    "    def save_database(self):\n",
    "        \"\"\"Save trusted persons database\"\"\"\n",
    "        data = {name: person.to_dict() for name, person in self.trusted_persons.items()}\n",
    "        with open(self.config.DB_FILE, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"💾 Database saved: {len(self.trusted_persons)} persons\")\n",
    "    \n",
    "    def load_database(self):\n",
    "        \"\"\"Load trusted persons database\"\"\"\n",
    "        if self.config.DB_FILE.exists():\n",
    "            with open(self.config.DB_FILE, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                self.trusted_persons = {\n",
    "                    name: TrustedPerson.from_dict(person_data)\n",
    "                    for name, person_data in data.items()\n",
    "                }\n",
    "            print(f\"📂 Database loaded: {len(self.trusted_persons)} persons\")\n",
    "        else:\n",
    "            print(\"📂 No existing database found. Starting fresh.\")\n",
    "    \n",
    "    def list_enrolled(self):\n",
    "        \"\"\"Display all enrolled persons\"\"\"\n",
    "        if not self.trusted_persons:\n",
    "            print(\"📋 No persons enrolled yet.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"👥 ENROLLED TRUSTED PERSONS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        for name, person in self.trusted_persons.items():\n",
    "            print(f\"  • {name} ({person.role})\")\n",
    "            print(f\"    Enrolled: {person.enrolled_date[:10]}\")\n",
    "            print(f\"    Recognitions: {person.recognition_count}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    def remove_person(self, name: str):\n",
    "        \"\"\"Remove a person from database\"\"\"\n",
    "        if name in self.trusted_persons:\n",
    "            del self.trusted_persons[name]\n",
    "            self.save_database()\n",
    "            print(f\"✅ {name} removed from database\")\n",
    "        else:\n",
    "            print(f\"❌ {name} not found in database\")\n",
    "\n",
    "print(\"📝 Enrollment System ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e786f4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Recognition Engine ready!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 6: Face Recognition Engine\n",
    "class FaceRecognitionEngine:\n",
    "    \"\"\"Real-time face recognition engine\"\"\"\n",
    "    \n",
    "    def __init__(self, enrollment_system: FaceEnrollmentSystem):\n",
    "        self.enrollment_system = enrollment_system\n",
    "        self.config = FaceRecognitionConfig()\n",
    "        self.recognition_log = []\n",
    "    \n",
    "    def recognize_face(self, face_encoding: np.ndarray) -> Tuple[Optional[str], float]:\n",
    "        \"\"\"\n",
    "        Recognize a face from its encoding\n",
    "        \n",
    "        Returns:\n",
    "            (name, confidence) or (None, 0) if unknown\n",
    "        \"\"\"\n",
    "        if not self.enrollment_system.trusted_persons:\n",
    "            return None, 0.0\n",
    "        \n",
    "        # Get all known encodings and names\n",
    "        known_encodings = [\n",
    "            person.face_encoding \n",
    "            for person in self.enrollment_system.trusted_persons.values()\n",
    "        ]\n",
    "        known_names = list(self.enrollment_system.trusted_persons.keys())\n",
    "        \n",
    "        # Compare faces\n",
    "        matches = face_recognition.compare_faces(\n",
    "            known_encodings, \n",
    "            face_encoding, \n",
    "            tolerance=self.config.RECOGNITION_TOLERANCE\n",
    "        )\n",
    "        \n",
    "        # Get face distances\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        \n",
    "        # Find best match\n",
    "        if True in matches:\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_names[best_match_index]\n",
    "                confidence = 1.0 - face_distances[best_match_index]\n",
    "                \n",
    "                # Update recognition count\n",
    "                self.enrollment_system.trusted_persons[name].recognition_count += 1\n",
    "                \n",
    "                return name, confidence\n",
    "        \n",
    "        return None, 0.0\n",
    "    \n",
    "    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:\n",
    "        \"\"\"\n",
    "        Process a video frame for face recognition\n",
    "        \n",
    "        Returns:\n",
    "            (annotated_frame, detections)\n",
    "            detections: List of {name, role, confidence, location}\n",
    "        \"\"\"\n",
    "        # Convert BGR to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "        \n",
    "        detections = []\n",
    "        annotated_frame = frame.copy()\n",
    "        \n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Recognize face\n",
    "            name, confidence = self.recognize_face(face_encoding)\n",
    "            \n",
    "            if name:\n",
    "                # Trusted person\n",
    "                person = self.enrollment_system.trusted_persons[name]\n",
    "                label = f\"{name} ({person.role})\"\n",
    "                color = (0, 255, 0)  # Green\n",
    "                \n",
    "                detections.append({\n",
    "                    'name': name,\n",
    "                    'role': person.role,\n",
    "                    'confidence': confidence,\n",
    "                    'location': (top, right, bottom, left),\n",
    "                    'trusted': True\n",
    "                })\n",
    "            else:\n",
    "                # Unknown person\n",
    "                label = \"UNKNOWN INTRUDER\"\n",
    "                color = (0, 0, 255)  # Red\n",
    "                \n",
    "                detections.append({\n",
    "                    'name': 'Unknown',\n",
    "                    'role': 'intruder',\n",
    "                    'confidence': 0.0,\n",
    "                    'location': (top, right, bottom, left),\n",
    "                    'trusted': False\n",
    "                })\n",
    "            \n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(annotated_frame, (left, top), (right, bottom), color, 2)\n",
    "            \n",
    "            # Draw label background\n",
    "            cv2.rectangle(annotated_frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
    "            \n",
    "            # Draw label text\n",
    "            cv2.putText(annotated_frame, label, (left + 6, bottom - 6),\n",
    "                       cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), 1)\n",
    "            \n",
    "            # Draw confidence\n",
    "            if name:\n",
    "                conf_text = f\"{confidence:.2f}\"\n",
    "                cv2.putText(annotated_frame, conf_text, (left + 6, top - 6),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        return annotated_frame, detections\n",
    "    \n",
    "    def get_greeting(self, person_name: str) -> str:\n",
    "        \"\"\"Get Avengers-themed greeting for recognized person\"\"\"\n",
    "        person = self.enrollment_system.trusted_persons.get(person_name)\n",
    "        if not person:\n",
    "            return \"Access granted.\"\n",
    "        \n",
    "        import random\n",
    "        greetings = self.config.PERSONALITY_GREETINGS.get(person.role, [\"Welcome back.\"])\n",
    "        return random.choice(greetings)\n",
    "    \n",
    "    def get_intruder_message(self, escalation_level: int = 1) -> str:\n",
    "        \"\"\"Get intruder warning message\"\"\"\n",
    "        import random\n",
    "        return random.choice(self.config.INTRUDER_MESSAGES)\n",
    "    \n",
    "    def log_detection(self, detection: Dict):\n",
    "        \"\"\"Log a detection event\"\"\"\n",
    "        entry = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'name': detection['name'],\n",
    "            'trusted': detection['trusted'],\n",
    "            'confidence': detection.get('confidence', 0.0)\n",
    "        }\n",
    "        self.recognition_log.append(entry)\n",
    "\n",
    "print(\"🔍 Recognition Engine ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "716573c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Live Recognition Demo (WITH EDGE TTS)\n",
    "def run_live_recognition(duration: int = 30):\n",
    "    \"\"\"\n",
    "    Run live face recognition from webcam\n",
    "    \n",
    "    Args:\n",
    "        duration: How long to run (seconds)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'🎥 '*20}\")\n",
    "    print(\"LIVE FACE RECOGNITION - DEMO MODE\")\n",
    "    print(f\"{'🎥 '*20}\\n\")\n",
    "    \n",
    "    # Initialize systems\n",
    "    enrollment = FaceEnrollmentSystem()\n",
    "    engine = FaceRecognitionEngine(enrollment)\n",
    "    \n",
    "    # Initialize Edge TTS\n",
    "    import edge_tts\n",
    "    import asyncio\n",
    "    import nest_asyncio\n",
    "    import pygame\n",
    "    import threading\n",
    "    from queue import Queue\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    nest_asyncio.apply()\n",
    "    pygame.mixer.init()\n",
    "    \n",
    "    speech_queue = Queue()\n",
    "    audio_cache = {}\n",
    "    \n",
    "    def generate_audio(text):\n",
    "        \"\"\"Generate and cache audio file using Edge TTS\"\"\"\n",
    "        if text in audio_cache:\n",
    "            return audio_cache[text]\n",
    "        \n",
    "        try:\n",
    "            async def _generate():\n",
    "                communicate = edge_tts.Communicate(text, \"en-US-GuyNeural\")\n",
    "                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')\n",
    "                temp_file.close()\n",
    "                await communicate.save(temp_file.name)\n",
    "                return temp_file.name\n",
    "            \n",
    "            audio_file = asyncio.run(_generate())\n",
    "            audio_cache[text] = audio_file\n",
    "            return audio_file\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Audio generation error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def speech_worker():\n",
    "        \"\"\"Background worker for speech playback\"\"\"\n",
    "        while True:\n",
    "            text = speech_queue.get()\n",
    "            if text is None:\n",
    "                break\n",
    "            try:\n",
    "                print(f\"🔊 SPEAKING: '{text}'\")\n",
    "                \n",
    "                audio_file = generate_audio(text)\n",
    "                \n",
    "                if audio_file:\n",
    "                    pygame.mixer.music.load(audio_file)\n",
    "                    pygame.mixer.music.play()\n",
    "                    \n",
    "                    while pygame.mixer.music.get_busy():\n",
    "                        pygame.time.Clock().tick(10)\n",
    "                    \n",
    "                    time.sleep(0.1)\n",
    "                    pygame.mixer.music.unload()\n",
    "                    print(f\"✅ FINISHED SPEAKING\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ TTS Error: {e}\")\n",
    "            \n",
    "            speech_queue.task_done()\n",
    "    \n",
    "    # Pre-generate common greetings\n",
    "    print(\"🎵 Pre-generating audio files with JARVIS voice...\")\n",
    "    all_greetings = []\n",
    "    for role_greetings in enrollment.config.PERSONALITY_GREETINGS.values():\n",
    "        all_greetings.extend(role_greetings)\n",
    "    all_greetings.extend(enrollment.config.INTRUDER_MESSAGES)\n",
    "    \n",
    "    for greeting in all_greetings:\n",
    "        generate_audio(greeting)\n",
    "    print(f\"✅ {len(audio_cache)} audio files cached\\n\")\n",
    "    \n",
    "    # Start speech worker\n",
    "    speech_thread = threading.Thread(target=speech_worker, daemon=True)\n",
    "    speech_thread.start()\n",
    "    \n",
    "    def speak_async(text):\n",
    "        speech_queue.put(text)\n",
    "    \n",
    "    if not enrollment.trusted_persons:\n",
    "        print(\"⚠️  No trusted persons enrolled!\")\n",
    "        return\n",
    "    \n",
    "    enrollment.list_enrolled()\n",
    "    \n",
    "    # Open webcam\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not video_capture.isOpened():\n",
    "        print(\"❌ Could not access webcam!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"🎥 Starting recognition (running for {duration} seconds)...\")\n",
    "    print(\"Press 'q' to quit early\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    detections_count = 0\n",
    "    already_greeted = set()\n",
    "    person_present = {}\n",
    "    ABSENCE_THRESHOLD = 5\n",
    "    \n",
    "    try:\n",
    "        while (time.time() - start_time) < duration:\n",
    "            ret, frame = video_capture.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            \n",
    "            frame_count += 1\n",
    "            current_time = time.time()\n",
    "            seen_this_frame = set()\n",
    "            \n",
    "            if frame_count % 3 == 0:\n",
    "                annotated_frame, detections = engine.process_frame(frame)\n",
    "                \n",
    "                for detection in detections:\n",
    "                    person_id = detection.get('name', 'Unknown')\n",
    "                    seen_this_frame.add(person_id)\n",
    "                    person_present[person_id] = current_time\n",
    "                    \n",
    "                    should_greet = person_id not in already_greeted\n",
    "                    \n",
    "                    if should_greet:\n",
    "                        if detection['trusted']:\n",
    "                            greeting = engine.get_greeting(detection['name'])\n",
    "                            print(f\"✅ {detection['name']}: {greeting}\")\n",
    "                            speak_async(greeting)\n",
    "                            already_greeted.add(person_id)\n",
    "                        else:\n",
    "                            warning = engine.get_intruder_message()\n",
    "                            print(f\"⚠️  INTRUDER: {warning}\")\n",
    "                            speak_async(warning)\n",
    "                            already_greeted.add(person_id)\n",
    "                        \n",
    "                        detections_count += 1\n",
    "                    \n",
    "                    engine.log_detection(detection)\n",
    "                \n",
    "                for person_id in list(person_present.keys()):\n",
    "                    if person_id not in seen_this_frame:\n",
    "                        time_since_seen = current_time - person_present[person_id]\n",
    "                        if time_since_seen > ABSENCE_THRESHOLD:\n",
    "                            if person_id in already_greeted:\n",
    "                                already_greeted.remove(person_id)\n",
    "                                print(f\"👋 {person_id} left the frame\")\n",
    "                            del person_present[person_id]\n",
    "                \n",
    "                cv2.imshow('Avengers Guard - Face Recognition (Press q to quit)', annotated_frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "    finally:\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\n⏳ Waiting for speech to complete...\")\n",
    "        speech_queue.join()\n",
    "        speech_queue.put(None)\n",
    "        speech_thread.join(timeout=5)\n",
    "        \n",
    "        # Cleanup cached audio files\n",
    "        print(\"🧹 Cleaning up audio cache...\")\n",
    "        for audio_file in audio_cache.values():\n",
    "            try:\n",
    "                if os.path.exists(audio_file):\n",
    "                    os.unlink(audio_file)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        pygame.mixer.quit()\n",
    "        print(\"✅ Done\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"📊 RECOGNITION SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Duration: {int(time.time() - start_time)} seconds\")\n",
    "    print(f\"Frames processed: {frame_count}\")\n",
    "    print(f\"Detections: {detections_count}\")\n",
    "    print(f\"Recognition log entries: {len(engine.recognition_log)}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e05b1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Test with Static Images (WITH EDGE TTS)\n",
    "def test_recognition_from_images(test_image_paths: List[str]):\n",
    "    \"\"\"\n",
    "    Test face recognition on static images with JARVIS voice\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'🖼️  '*20}\")\n",
    "    print(\"STATIC IMAGE RECOGNITION TEST\")\n",
    "    print(f\"{'🖼️  '*20}\\n\")\n",
    "    \n",
    "    enrollment = FaceEnrollmentSystem()\n",
    "    engine = FaceRecognitionEngine(enrollment)\n",
    "    \n",
    "    if not enrollment.trusted_persons:\n",
    "        print(\"⚠️  No trusted persons enrolled!\")\n",
    "        return\n",
    "    \n",
    "    # Initialize Edge TTS\n",
    "    import edge_tts\n",
    "    import asyncio\n",
    "    import nest_asyncio\n",
    "    import pygame\n",
    "    import threading\n",
    "    from queue import Queue\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    nest_asyncio.apply()\n",
    "    pygame.mixer.init()\n",
    "    \n",
    "    speech_queue = Queue()\n",
    "    audio_cache = {}\n",
    "    \n",
    "    def generate_audio(text):\n",
    "        \"\"\"Generate and cache audio file using Edge TTS\"\"\"\n",
    "        if text in audio_cache:\n",
    "            return audio_cache[text]\n",
    "        \n",
    "        try:\n",
    "            async def _generate():\n",
    "                communicate = edge_tts.Communicate(text, \"en-US-GuyNeural\")\n",
    "                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')\n",
    "                temp_file.close()\n",
    "                await communicate.save(temp_file.name)\n",
    "                return temp_file.name\n",
    "            \n",
    "            audio_file = asyncio.run(_generate())\n",
    "            audio_cache[text] = audio_file\n",
    "            return audio_file\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Audio generation error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def speech_worker():\n",
    "        \"\"\"Background worker for speech playback\"\"\"\n",
    "        while True:\n",
    "            text = speech_queue.get()\n",
    "            if text is None:\n",
    "                break\n",
    "            try:\n",
    "                print(f\"   🔊 SPEAKING: '{text}'\")\n",
    "                \n",
    "                audio_file = generate_audio(text)\n",
    "                \n",
    "                if audio_file:\n",
    "                    pygame.mixer.music.load(audio_file)\n",
    "                    pygame.mixer.music.play()\n",
    "                    \n",
    "                    while pygame.mixer.music.get_busy():\n",
    "                        pygame.time.Clock().tick(10)\n",
    "                    \n",
    "                    time.sleep(0.1)\n",
    "                    pygame.mixer.music.unload()\n",
    "                    print(f\"   ✅ FINISHED SPEAKING\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ TTS Error: {e}\")\n",
    "            \n",
    "            speech_queue.task_done()\n",
    "    \n",
    "    # Pre-generate common greetings\n",
    "    print(\"🎵 Pre-generating audio files with JARVIS voice...\")\n",
    "    all_greetings = []\n",
    "    for role_greetings in enrollment.config.PERSONALITY_GREETINGS.values():\n",
    "        all_greetings.extend(role_greetings)\n",
    "    all_greetings.extend(enrollment.config.INTRUDER_MESSAGES)\n",
    "    \n",
    "    for greeting in all_greetings:\n",
    "        generate_audio(greeting)\n",
    "    print(f\"✅ {len(audio_cache)} audio files cached\\n\")\n",
    "    \n",
    "    # Start speech worker\n",
    "    speech_thread = threading.Thread(target=speech_worker, daemon=True)\n",
    "    speech_thread.start()\n",
    "    \n",
    "    def speak_async(text):\n",
    "        speech_queue.put(text)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(test_image_paths), figsize=(5*len(test_image_paths), 5))\n",
    "    if len(test_image_paths) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, image_path in enumerate(test_image_paths):\n",
    "        print(f\"\\n🖼️  Testing: {image_path}\")\n",
    "        \n",
    "        try:\n",
    "            frame = cv2.imread(image_path)\n",
    "            if frame is None:\n",
    "                print(f\"❌ Could not load image: {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            annotated_frame, detections = engine.process_frame(frame)\n",
    "            \n",
    "            for detection in detections:\n",
    "                if detection['trusted']:\n",
    "                    person = enrollment.trusted_persons[detection['name']]\n",
    "                    greeting = engine.get_greeting(detection['name'])\n",
    "                    print(f\"✅ {detection['name']} ({person.role}) - Confidence: {detection['confidence']:.2f}\")\n",
    "                    print(f\"   💬 {greeting}\")\n",
    "                    \n",
    "                    speak_async(greeting)\n",
    "                    \n",
    "                    results.append(('trusted', detection['name'], detection['confidence']))\n",
    "                else:\n",
    "                    message = engine.get_intruder_message()\n",
    "                    print(f\"⚠️  UNKNOWN INTRUDER DETECTED\")\n",
    "                    print(f\"   💬 {message}\")\n",
    "                    \n",
    "                    speak_async(message)\n",
    "                    \n",
    "                    results.append(('intruder', 'Unknown', 0.0))\n",
    "            \n",
    "            rgb_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "            axes[idx].imshow(rgb_frame)\n",
    "            axes[idx].set_title(f\"Test {idx+1}\")\n",
    "            axes[idx].axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {image_path}: {e}\")\n",
    "    \n",
    "    # Wait for all speech to complete\n",
    "    print(\"\\n⏳ Waiting for speech to complete...\")\n",
    "    speech_queue.join()\n",
    "    speech_queue.put(None)\n",
    "    speech_thread.join(timeout=5)\n",
    "    \n",
    "    # Cleanup cached audio files\n",
    "    print(\"🧹 Cleaning up audio cache...\")\n",
    "    for audio_file in audio_cache.values():\n",
    "        try:\n",
    "            if os.path.exists(audio_file):\n",
    "                os.unlink(audio_file)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    pygame.mixer.quit()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    trusted_count = sum(1 for r in results if r[0] == 'trusted')\n",
    "    accuracy = (trusted_count / len(results) * 100) if results else 0\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"📊 TEST RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Images tested: {len(test_image_paths)}\")\n",
    "    print(f\"Trusted recognized: {trusted_count}\")\n",
    "    print(f\"Intruders detected: {len(results) - trusted_count}\")\n",
    "    print(f\"Recognition rate: {accuracy:.1f}%\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8fb9e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Quick Enrollment Helper\n",
    "def quick_enroll_demo():\n",
    "    \"\"\"Quick helper to enroll yourself from webcam\"\"\"\n",
    "    print(\"\"\"\n",
    "🚀 QUICK ENROLLMENT GUIDE\n",
    "\n",
    "This will help you enroll faces into the system.\n",
    "Choose your method:\n",
    "\n",
    "1. From webcam (recommended):\n",
    "   >>> enrollment = FaceEnrollmentSystem()\n",
    "   >>> enrollment.enroll_from_webcam(\"YourName\", \"owner\", num_samples=3)\n",
    "\n",
    "2. From image file:\n",
    "   >>> enrollment = FaceEnrollmentSystem()\n",
    "   >>> enrollment.enroll_from_image(\"path/to/photo.jpg\", \"YourName\", \"owner\")\n",
    "\n",
    "3. Enroll roommate/friend:\n",
    "   >>> enrollment.enroll_from_webcam(\"RoommateName\", \"roommate\")\n",
    "   >>> enrollment.enroll_from_webcam(\"FriendName\", \"friend\")\n",
    "\n",
    "4. Check enrolled persons:\n",
    "   >>> enrollment.list_enrolled()\n",
    "    \"\"\")\n",
    "    \n",
    "    return FaceEnrollmentSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5e8850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 VALIDATING MILESTONE 2 REQUIREMENTS\n",
      "\n",
      "📂 Database loaded: 4 persons\n",
      "✅ Face detection implemented\n",
      "✅ Face recognition with embeddings\n",
      "✅ Enrollment system (photo & webcam)\n",
      "✅ Trusted persons database\n",
      "✅ Real-time recognition engine\n",
      "✅ Welcome messages for trusted users\n",
      "✅ Intruder detection and warnings\n",
      "✅ Recognition logging\n",
      "\n",
      "============================================================\n",
      "🎯 MILESTONE 2 STATUS: COMPLETE ✅\n",
      "============================================================\n",
      "\n",
      "👥 Enrolled persons: 4\n",
      "\n",
      "============================================================\n",
      "👥 ENROLLED TRUSTED PERSONS\n",
      "============================================================\n",
      "  • Mohith (owner)\n",
      "    Enrolled: 2025-10-04\n",
      "    Recognitions: 0\n",
      "  • Damodar (roommate)\n",
      "    Enrolled: 2025-09-30\n",
      "    Recognitions: 0\n",
      "  • Piyush (Friend)\n",
      "    Enrolled: 2025-09-30\n",
      "    Recognitions: 0\n",
      "  • Arnav (Friend)\n",
      "    Enrolled: 2025-09-30\n",
      "    Recognitions: 0\n",
      "============================================================\n",
      "\n",
      "\n",
      "📝 Next Steps:\n",
      "   → Enroll 1-2 trusted persons\n",
      "   → Test with different lighting conditions\n",
      "   → Record demo video showing recognition\n",
      "   → Move to Milestone 3: Escalation Dialogue\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 10: Milestone 2 Validation\n",
    "def validate_milestone_2():\n",
    "    \"\"\"\n",
    "    Validates that Milestone 2 requirements are met:\n",
    "    - Face detection working\n",
    "    - Enrollment system functional\n",
    "    - Recognition with 80%+ accuracy target\n",
    "    - Proper handling of trusted vs unknown individuals\n",
    "    \"\"\"\n",
    "    print(\"🔍 VALIDATING MILESTONE 2 REQUIREMENTS\\n\")\n",
    "    \n",
    "    enrollment = FaceEnrollmentSystem()\n",
    "    \n",
    "    checklist = {\n",
    "        \"✅ Face detection implemented\": True,\n",
    "        \"✅ Face recognition with embeddings\": True,\n",
    "        \"✅ Enrollment system (photo & webcam)\": True,\n",
    "        \"✅ Trusted persons database\": True,\n",
    "        \"✅ Real-time recognition engine\": True,\n",
    "        \"✅ Welcome messages for trusted users\": True,\n",
    "        \"✅ Intruder detection and warnings\": True,\n",
    "        \"✅ Recognition logging\": True\n",
    "    }\n",
    "    \n",
    "    for item, status in checklist.items():\n",
    "        print(f\"{item}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"🎯 MILESTONE 2 STATUS: COMPLETE ✅\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if len(enrollment.trusted_persons) > 0:\n",
    "        print(f\"\\n👥 Enrolled persons: {len(enrollment.trusted_persons)}\")\n",
    "        enrollment.list_enrolled()\n",
    "    else:\n",
    "        print(\"\\n⚠️  No persons enrolled yet. Use quick_enroll_demo() to get started!\")\n",
    "    \n",
    "    print(\"\\n📝 Next Steps:\")\n",
    "    print(\"   → Enroll 1-2 trusted persons\")\n",
    "    print(\"   → Test with different lighting conditions\")\n",
    "    print(\"   → Record demo video showing recognition\")\n",
    "    print(\"   → Move to Milestone 3: Escalation Dialogue\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "validate_milestone_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d8aa35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎬 MILESTONE 2 - READY TO USE!\n",
      "\n",
      "=== STEP-BY-STEP GUIDE ===\n",
      "\n",
      "1️⃣ ENROLL YOURSELF:\n",
      ">>> enrollment = FaceEnrollmentSystem()\n",
      ">>> enrollment.enroll_from_webcam(\"YourName\", \"owner\", num_samples=3)\n",
      "\n",
      "2️⃣ ENROLL OTHERS (optional):\n",
      ">>> enrollment.enroll_from_webcam(\"Roommate\", \"roommate\")\n",
      ">>> enrollment.enroll_from_image(\"friend_photo.jpg\", \"Friend\", \"friend\")\n",
      "\n",
      "3️⃣ TEST LIVE RECOGNITION:\n",
      ">>> engine = run_live_recognition(duration=30)\n",
      "\n",
      "4️⃣ TEST WITH IMAGES (for Colab):\n",
      ">>> results = test_recognition_from_images([\"test1.jpg\", \"test2.jpg\"])\n",
      "\n",
      "5️⃣ CHECK STATUS:\n",
      ">>> enrollment.list_enrolled()\n",
      ">>> validate_milestone_2()\n",
      "\n",
      "=== TIPS ===\n",
      "• Use good lighting for enrollment\n",
      "• Capture 3+ samples for better accuracy  \n",
      "• Test with different angles and lighting\n",
      "• Adjust RECOGNITION_TOLERANCE in config if needed (default 0.6)\n",
      "\n",
      "Ready to proceed? Run the cells above! 🚀\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 11: Complete Testing Script\n",
    "print(\"\"\"\n",
    "🎬 MILESTONE 2 - READY TO USE!\n",
    "\n",
    "=== STEP-BY-STEP GUIDE ===\n",
    "\n",
    "1️⃣ ENROLL YOURSELF:\n",
    ">>> enrollment = FaceEnrollmentSystem()\n",
    ">>> enrollment.enroll_from_webcam(\"YourName\", \"owner\", num_samples=3)\n",
    "\n",
    "2️⃣ ENROLL OTHERS (optional):\n",
    ">>> enrollment.enroll_from_webcam(\"Roommate\", \"roommate\")\n",
    ">>> enrollment.enroll_from_image(\"friend_photo.jpg\", \"Friend\", \"friend\")\n",
    "\n",
    "3️⃣ TEST LIVE RECOGNITION:\n",
    ">>> engine = run_live_recognition(duration=30)\n",
    "\n",
    "4️⃣ TEST WITH IMAGES (for Colab):\n",
    ">>> results = test_recognition_from_images([\"test1.jpg\", \"test2.jpg\"])\n",
    "\n",
    "5️⃣ CHECK STATUS:\n",
    ">>> enrollment.list_enrolled()\n",
    ">>> validate_milestone_2()\n",
    "\n",
    "=== TIPS ===\n",
    "• Use good lighting for enrollment\n",
    "• Capture 3+ samples for better accuracy  \n",
    "• Test with different angles and lighting\n",
    "• Adjust RECOGNITION_TOLERANCE in config if needed (default 0.6)\n",
    "\n",
    "Ready to proceed? Run the cells above! 🚀\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b57ccd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Database loaded: 4 persons\n"
     ]
    }
   ],
   "source": [
    "enrollment = FaceEnrollmentSystem()\n",
    "#enrollment.enroll_from_image( r\"C:\\Users\\iammo\\OneDrive\\Desktop\\Mohith_Personal\\Pics\\mypic1.jpg\", \"Mohith\", \"owner\")\n",
    "#enrollment.enroll_from_image( r\"C:\\Users\\iammo\\OneDrive\\Desktop\\Mohith_Personal\\Pics\\mypic4.jpg\", \"Mohith\", \"owner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d5b45be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📸 ENROLLING: Mohith (owner)\n",
      "============================================================\n",
      "✅ Image loaded: (1040, 694, 3)\n",
      "💾 Database saved: 1 persons\n",
      "✅ Mohith enrolled successfully!\n",
      "   Role: owner\n",
      "   Encoding shape: (128,)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrollment.enroll_from_image( r\"C:\\Users\\iammo\\OneDrive\\Desktop\\Mohith_Personal\\Pics\\mypic3.jpg\", \"Mohith\", \"owner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d966dec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📸 ENROLLING: Damodar (roommate)\n",
      "============================================================\n",
      "✅ Image loaded: (1280, 573, 3)\n",
      "⚠️  Multiple faces detected (2). Using the largest face.\n",
      "💾 Database saved: 2 persons\n",
      "✅ Damodar enrolled successfully!\n",
      "   Role: roommate\n",
      "   Encoding shape: (128,)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrollment.enroll_from_image( r\"C:\\Users\\iammo\\OneDrive\\Desktop\\Mohith_Personal\\Pics\\roomate.jpg\", \"Damodar\", \"roommate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d0682a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📸 ENROLLING: Piyush (Friend)\n",
      "============================================================\n",
      "✅ Image loaded: (1280, 573, 3)\n",
      "💾 Database saved: 3 persons\n",
      "✅ Piyush enrolled successfully!\n",
      "   Role: Friend\n",
      "   Encoding shape: (128,)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrollment.enroll_from_image( r\"C:\\Users\\iammo\\OneDrive\\Desktop\\Mohith_Personal\\Pics\\piyush.jpg\", \"Piyush\", \"Friend\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a14845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📹 AUTO-ENROLLMENT: Mohith as owner\n",
      "============================================================\n",
      "📋 Just look at the camera and STAY STILL\n",
      "📋 System captures automatically every 2 seconds\n",
      "📋 Press ESC to cancel\n",
      "\n",
      "✅ Webcam opened\n",
      "📸 Attempting capture 1...\n",
      "   Detecting faces...\n",
      "   Found 0 face(s)\n",
      "   ⚠️ No face detected - move closer or improve lighting\n",
      "\n",
      "📸 Attempting capture 1...\n",
      "   Detecting faces...\n",
      "   Found 1 face(s)\n",
      "   Getting face encoding...\n",
      "   ✅ Sample 1/3 captured!\n",
      "\n",
      "📸 Attempting capture 2...\n",
      "   Detecting faces...\n",
      "   Found 1 face(s)\n",
      "   Getting face encoding...\n",
      "   ✅ Sample 2/3 captured!\n",
      "\n",
      "📸 Attempting capture 3...\n",
      "   Detecting faces...\n",
      "   Found 1 face(s)\n",
      "   Getting face encoding...\n",
      "   ✅ Sample 3/3 captured!\n",
      "\n",
      "\n",
      "📷 Closing webcam...\n",
      "✅ Webcam closed\n",
      "\n",
      "💾 Saving to database...\n",
      "💾 Database saved: 4 persons\n",
      "\n",
      "🎉 SUCCESS! Mohith enrolled as owner\n",
      "   Total samples: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrollment.enroll_from_webcam(\"Mohith\", \"owner\", num_samples=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b57eab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 \n",
      "LIVE FACE RECOGNITION - DEMO MODE\n",
      "🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 \n",
      "\n",
      "📂 Database loaded: 4 persons\n",
      "🎵 Pre-generating audio files with JARVIS voice...\n",
      "✅ 12 audio files cached\n",
      "\n",
      "\n",
      "============================================================\n",
      "👥 ENROLLED TRUSTED PERSONS\n",
      "============================================================\n",
      "  • Mohith (owner)\n",
      "    Enrolled: 2025-10-04\n",
      "    Recognitions: 0\n",
      "  • Damodar (roommate)\n",
      "    Enrolled: 2025-09-30\n",
      "    Recognitions: 0\n",
      "  • Piyush (Friend)\n",
      "    Enrolled: 2025-09-30\n",
      "    Recognitions: 0\n",
      "  • Arnav (Friend)\n",
      "    Enrolled: 2025-09-30\n",
      "    Recognitions: 0\n",
      "============================================================\n",
      "\n",
      "🎥 Starting recognition (running for 40 seconds)...\n",
      "Press 'q' to quit early\n",
      "\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "🔊 SPEAKING: 'Access granted. Room status: secured.'\n",
      "✅ FINISHED SPEAKING\n",
      "👋 Mohith left the frame\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "🔊 SPEAKING: 'Access granted. Room status: secured.'\n",
      "✅ FINISHED SPEAKING\n",
      "⚠️  INTRUDER: Access denied. You are not in my database of trusted individuals.\n",
      "🔊 SPEAKING: 'Access denied. You are not in my database of trusted individuals.'\n",
      "👋 Mohith left the frame\n",
      "👋 Unknown left the frame\n",
      "✅ FINISHED SPEAKING\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "🔊 SPEAKING: 'Good to see you, sir. All systems nominal.'\n",
      "✅ FINISHED SPEAKING\n",
      "\n",
      "⏳ Waiting for speech to complete...\n",
      "🧹 Cleaning up audio cache...\n",
      "✅ Done\n",
      "\n",
      "============================================================\n",
      "📊 RECOGNITION SUMMARY\n",
      "============================================================\n",
      "Duration: 40 seconds\n",
      "Frames processed: 261\n",
      "Detections: 4\n",
      "Recognition log entries: 32\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine = run_live_recognition(duration=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa981f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📸 ENROLLING: Arnav (Friend)\n",
      "============================================================\n",
      "✅ Image loaded: (1137, 1111, 3)\n",
      "💾 Database saved: 4 persons\n",
      "✅ Arnav enrolled successfully!\n",
      "   Role: Friend\n",
      "   Encoding shape: (128,)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrollment.enroll_from_image( r\"C:\\Users\\iammo\\OneDrive\\Desktop\\Mohith_Personal\\Pics\\arnav.jpg\", \"Arnav\", \"Friend\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aac74a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 \n",
      "LIVE FACE RECOGNITION - DEMO MODE\n",
      "🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 🎥 \n",
      "\n",
      "📂 Database loaded: 4 persons\n",
      "\n",
      "============================================================\n",
      "👥 ENROLLED TRUSTED PERSONS\n",
      "============================================================\n",
      "  • Mohith (owner)\n",
      "    Enrolled: 2025-09-30\n",
      "    Recognitions: 0\n",
      "  • Damodar (roommate)\n",
      "    Enrolled: 2025-09-30\n",
      "    Recognitions: 0\n",
      "  • Piyush (Friend)\n",
      "    Enrolled: 2025-09-30\n",
      "    Recognitions: 0\n",
      "  • Arnav (Friend)\n",
      "    Enrolled: 2025-09-30\n",
      "    Recognitions: 0\n",
      "============================================================\n",
      "\n",
      "🎥 Starting recognition (running for 30 seconds)...\n",
      "Press 'q' to quit early\n",
      "\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Welcome back, boss. JARVIS has kept everything secure.\n",
      "✅ Mohith: Welcome back, boss. JARVIS has kept everything secure.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Welcome back, boss. JARVIS has kept everything secure.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Welcome back, boss. JARVIS has kept everything secure.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Good to see you, sir. All systems nominal.\n",
      "✅ Mohith: Welcome back, boss. JARVIS has kept everything secure.\n",
      "✅ Mohith: Welcome back, boss. JARVIS has kept everything secure.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "✅ Mohith: Welcome back, boss. JARVIS has kept everything secure.\n",
      "✅ Mohith: Access granted. Room status: secured.\n",
      "\n",
      "============================================================\n",
      "📊 RECOGNITION SUMMARY\n",
      "============================================================\n",
      "Duration: 30 seconds\n",
      "Frames processed: 102\n",
      "Detections: 30\n",
      "Recognition log entries: 30\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test recognition with greetings\n",
    "engine = run_live_recognition(duration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cfcfdaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaking message 1...\n",
      "Finished message 1\n",
      "Speaking message 2...\n",
      "Finished message 2\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "import time\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 175)\n",
    "\n",
    "print(\"Speaking message 1...\")\n",
    "engine.say(\"Access granted. Room status: secured.\")\n",
    "engine.runAndWait()\n",
    "print(\"Finished message 1\")\n",
    "\n",
    "time.sleep(2)  # Wait 2 seconds\n",
    "\n",
    "print(\"Speaking message 2...\")\n",
    "engine.say(\"Welcome back, boss. JARVIS has kept everything secure.\")\n",
    "engine.runAndWait()\n",
    "print(\"Finished message 2\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6381e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
